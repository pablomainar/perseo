{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib widget\n",
    "\n",
    "from dataset import OCRDataset\n",
    "from trainer import Trainer\n",
    "from transformers import VisionEncoderDecoderModel, BeitImageProcessor, RobertaTokenizer\n",
    "from transformers import BeitConfig, RobertaConfig, VisionEncoderDecoderConfig\n",
    "from PIL import Image\n",
    "import requests\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision.io import read_image\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision\n",
    "import os\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from peft import LoraConfig, get_peft_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and plot the losses\n",
    "\n",
    "train_losses = torch.load(\"models/train_losses_59.pt\")\n",
    "test_losses = torch.load(\"models/test_losses_59.pt\")\n",
    "plt.figure()\n",
    "plt.plot(train_losses, label=\"train\")\n",
    "plt.plot(test_losses, label=\"test\")\n",
    "plt.legend([\"train\", \"test\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model\n",
    "model_path = \"models/model_59.pt\"\n",
    "device = torch.device('cuda:1' if torch.cuda.is_available() else 'cpu')\n",
    "tokenizer = RobertaTokenizer.from_pretrained('PlanTL-GOB-ES/roberta-base-bne')\n",
    "model_trocr = VisionEncoderDecoderModel.from_pretrained(\"microsoft/trocr-small-stage1\")\n",
    "encoder = model_trocr.encoder\n",
    "encoder.save_pretrained(\"pretrained_encoder\")\n",
    "encoder_config = encoder.config\n",
    "encoder_config.image_size = (64,2304) \n",
    "model = VisionEncoderDecoderModel.from_encoder_decoder_pretrained(\"pretrained_encoder\", 'PlanTL-GOB-ES/roberta-base-bne', encoder_config=encoder_config) \n",
    "config = LoraConfig(\n",
    "    r=16,\n",
    "    lora_alpha=16,\n",
    "    target_modules=[\"query\", \"value\"],\n",
    "    lora_dropout=0.1,\n",
    "    bias=\"none\",\n",
    "    modules_to_save=[\"classifier\"],\n",
    ")\n",
    "model = get_peft_model(model, config)\n",
    "\n",
    "model.config.decoder_start_token_id = tokenizer.cls_token_id\n",
    "model.config.pad_token_id = tokenizer.pad_token_id\n",
    "model.config.vocab_size = model.config.decoder.vocab_size\n",
    "model.config.eos_token_id = tokenizer.sep_token_id\n",
    "model.config.max_length = 64\n",
    "model.config.early_stopping = True\n",
    "model.config.no_repeat_ngram_size = 3\n",
    "model.config.length_penalty = 2.0\n",
    "model.config.num_beams = 4\n",
    "\n",
    "#model.load_lora_weights(\"models/model_0.pt\")\n",
    "model.load_state_dict(torch.load(model_path))\n",
    "model.to(device)\n",
    "\n",
    "\n",
    "# Load the dataset\n",
    "dataset = OCRDataset(characters_mode=\"typed\", tokenizer=tokenizer, device=device, test=True)\n",
    "dataloader = DataLoader(dataset, batch_size=1, shuffle=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the first item from the dataset\n",
    "image, label, mask = next(iter(dataloader))\n",
    "image = image.to(device)\n",
    "mask = mask[0]\n",
    "nb_ids_label = [1 if mask[i] == 1 else 0 for i in range(len(mask))]\n",
    "nb_ids_label = np.sum(nb_ids_label)\n",
    "label = label[:,:nb_ids_label]\n",
    "label = tokenizer.batch_decode(label, skip_special_tokens=True)\n",
    "# Make inference\n",
    "with torch.no_grad():\n",
    "    generated_ids = model.generate(image)\n",
    "    generated_text = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)\n",
    "\n",
    "print(\"True label: \", label[0])\n",
    "print(\"Generated text: \", generated_text[0])\n",
    "plt.figure()\n",
    "plt.imshow(image.squeeze(0).permute(1,2,0).cpu().detach().numpy())\n",
    "\n",
    "'''input_ids = tokenizer.convert_tokens_to_ids([tokenizer.bos_token])\n",
    "input_ids = torch.tensor(input_ids).unsqueeze(0).to(device)\n",
    "output = model(image, decoder_input_ids=input_ids)\n",
    "logits = output.logits\n",
    "softmax = torch.softmax(logits, dim=-1)\n",
    "values,idxs = torch.topk(softmax, k=30, dim=-1)#.cpu().numpy()[0][0]\n",
    "values = values.cpu().detach().numpy()[0,0]\n",
    "idxs = idxs.cpu().detach().numpy()[0,0]\n",
    "print(values)\n",
    "print(idxs)\n",
    "tokens = tokenizer.convert_ids_to_tokens(idxs)\n",
    "print(tokens)'''\n",
    "print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "perseo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
